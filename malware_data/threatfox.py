import requests
import json
import datetime
import os

# Global parameters
API_URL = "https://threatfox-api.abuse.ch/api/v1/"
API_KEY = "YOUR_API_KEY"  # Replace "YOUR_API_KEY" with your actual API key

class ThreatFox:
    def __init__(self, api_url=API_URL, api_key=API_KEY):
        self.api_url = api_url
        self.api_key = api_key
    
    def fetch_recent_iocs(self, days=1):
        payload = {
            "query": "get_iocs",
            "days": days
        }
        response = requests.post(self.api_url, json=payload)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"Failed to fetch data. Status code: {response.status_code}")
            return None

class DataHandler:
    def __init__(self) -> None:
        self.corpus = None
        
        
    def save_data(self, data, file_path='./loading_files/threatfox'):
        if not os.path.exists(file_path):
            os.makedirs(file_path)
        file_name = datetime.datetime.now().strftime("%Y-%m-%d") + ".json"
        with open(os.path.join(file_path, file_name), 'w') as file:
            
            domains = {"domains": data['data']}
            json.dump(domains, file)
            
            
    def clear_duplicates(self, target_data):
        source_data = self.corpus
        
        # extract 'id': '389930', 'ioc_value' from corpus
        corpus_index = {}
        for ioc in source_data:
            corpus_index[ioc['id']] = ioc['ioc_value']
            corpus_index[ioc['ioc_value']] = ioc['id']
            
        print("Built corpus index containing: ", len(corpus_index), "entries.")
        
        
        target_index = {}
        for ioc in target_data:
            target_index[ioc['id']] = ioc['ioc_value']
            target_index[ioc['ioc_value']] = ioc['id']
            
        print("Built target index containing: ", len(target_index), "entries.")
            
        # start timer
        timer = datetime.datetime.now()
        # Compare indexes
        d_count = 0
        for key in target_index:
            if key in corpus_index:
                print(f"Duplicate found: {key}")
                d_count += 1
                target_data['data'].remove(target_index[key])
        
        # end timer
        timer = datetime.datetime.now() - timer
        print(f"Found {d_count} duplicates in {timer} seconds.")
         
    
    def load_data(self, file_path='./loading_files/threatfox', update_corpus=True):
        files = [f for f in os.listdir(file_path) if os.path.isfile(os.path.join(file_path, f))]
        merged_data = []
        for file in files:
            with open(os.path.join(file_path, file)) as f:
                data = json.load(f)
                merged_data.extend(data['domains'])
                
                
        print(f"Loaded {len(files)} files.")
        print(f"Loaded {len(merged_data)} domains.")
        if self.corpus is None:
            self.corpus = merged_data
        elif update_corpus:
            self.corpus.extend(data['domains'])
        return merged_data

if __name__ == "__main__":
    tf = ThreatFox()
    dh = DataHandler()
    iocs = tf.fetch_recent_iocs(days=7)
    
    dh.save_data(iocs)
    
    #dh.load_data()
   # dh.clear_duplicates(iocs)